{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "# Reddit API\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Clean dataframe\n",
    "\n",
    "# Remove stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Extract names from spacy library\n",
    "import spacy\n",
    "\n",
    "# Dataframe numerical manipulation\n",
    "import numpy as np\n",
    "\n",
    "# Sentiment analysis\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import difflib\n",
    "\n",
    "# Removing punctuation and data cleaning post sentiment analysis\n",
    "import string\n",
    "\n",
    "# Webscraper libraries\n",
    "from selenium import webdriver\n",
    "import urllib.request\n",
    "import os\n",
    "from time import sleep\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageOps\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Reddit API:\n",
    "client_id = 'ptyAAVrgtcJZCzNytlTtJA'\n",
    "with open('secret.txt', 'r') as f:\n",
    "    secret_key = f.read()\n",
    "\n",
    "auth = requests.auth.HTTPBasicAuth(client_id, secret_key)\n",
    "\n",
    "with open('pw.txt', 'r') as f:\n",
    "    pw = f.read()\n",
    "\n",
    "with open('user.txt', 'r') as f:\n",
    "    user = f.read()\n",
    "\n",
    "data = {\n",
    "    'grant_type': 'password',\n",
    "    'username': user,\n",
    "    'password': pw\n",
    "}\n",
    "\n",
    "headers = {'user-agent': 'myapi/0.0.1'}\n",
    "\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=auth, data=data, headers=headers)\n",
    "\n",
    "TOKEN = res.json()['access_token']\n",
    "\n",
    "headers['Authorization'] = f'bearer {TOKEN}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What to do when I’m going for collar chokes or sleeve control but accidentally stick my thumb under the rashguard that’s underneath the Gi?\n",
      "Inspired by another post and this was too long a story to be a comment\n",
      "Mixing Adderal and training, good idea or bad idea?\n",
      "Brazilian Jiu Jitsu can now form part of GCSE Curriculum in Physical Education - UKBJJA\n",
      "Deep dive\n",
      "safety rules for a massive man?\n",
      "When do you know what your BJJ ‘game’ is?\n",
      "Andrew Wiltse coming back to competition soon\n",
      "White Belt Wednesday\n",
      "No Holds Barred Q&amp;A: Nicky Ryan-Craig Jones\n",
      "When did you start competing?\n",
      "A lot of people on r/bjj would not be able to train at normal/traditional Judo school.\n",
      "offering reasonably priced Sunday class in Taiwan\n",
      "Kron is back! Fights Charles Jourdain on May 6th\n",
      "Judo terms in BJJ\n",
      "Why BJJ people suck at takedowns\n",
      "VHTS shorts\n",
      "What submissions are the easiest to pull on people with no BJJ experience?\n",
      "Does the pass determine the guard, or vise versa?\n",
      "Exhausted Arms\n",
      "Anyone who has trained or currently is under Danaher, what is it like ?\n",
      "Honestly, would you rather be promoted a belt with a ceremony and everything, but told privately by your coach they don't think you actually earned it, or work for a promotion and get publicly passed over, but privately told your coach thinks you're actually good enough for the next belt up.\n",
      "first tournament coming up. pretty nervous.\n",
      "Aspiring grappling coach for mma\n",
      "If you’re a skinny technical guy under 145 lbs, you are my favorite training partner\n",
      "Gym Owners: I’m developing an app to manage your entire business. Are you interested to try for free?\n",
      "Alexa Grasso shares her RNC technique\n",
      "I know these types of posts pop up probably to an annoying degree to experienced practitioners but nevertheless, here we go:\n",
      "coach/black belt appreciaction post\n",
      "Club recommendation request: Amarillo/Panhandle Texas\n",
      "Why is Cyborg doing Grappling Industries…\n",
      "Where to find bjj shorts that fit a 43 1/2\" waist?\n",
      "Please help me make a decision...\n",
      "Does beginners classes have rolling time in your gym?\n",
      "Those of you who train a lot (10+ hours a week) how do you maintain and regulate your levels of intensity?\n",
      "Some Single Leg action during competition class 🫡\n",
      "Try this guard pass drill‼️\n",
      "pressure vs intensity\n",
      "My BJJ game consists mostly of spamming take down and hunting for toe holds. What should I add and work on to maximize the effectiveness of this approach?\n",
      "Opinion: The gentle art can be so brutal that it would the most optimal for torpedos\n",
      "Training with splenomegaly.\n",
      "How applicable is a loose open guard applicable to mma/self defense?\n",
      "Sick front headlock counter from two on one\n",
      "Buying Gi's in Brazil (Rio vs. Sao Paulo)\n",
      "What to do while sitting out due to injury\n",
      "Bad Habits From Wrestling\n",
      "Black Belts, what is the weakest part of your game and how are you personally going about strengthening it?\n",
      "What is it like to get choked out?\n",
      "thoughts on bjj beltchecker ?\n",
      "Going Abroad to Train\n",
      "What did Oleinik do with his legs during this takedown?\n",
      "Has anyone here been suspended/ban from their gym? How did it go down?\n",
      "Options after a Leg Attack\n",
      "Very Rare BJ Penn BJJ Match vs Marcos Escobar (BROWN BELT vs BLACK BELT) 😱\n",
      "Black Belt vs White Belt with 6 years wrestling. Black belt didn’t know. Hahaha.\n",
      "Why blue belts quit. My thoughts.\n",
      "Traumatized and open to suggestions\n",
      "Origin Rashguards\n",
      "No-Gi Shorts Question\n",
      "getting caught in Z guard. No gi and gi options?\n",
      "Dissecting the Offense of Gordon Ryan - ADCC 2017\n",
      "open mats in Toronto.\n",
      "Any smaller guys mess with 2 on 1 guard?\n",
      "Another great video dropped by Legion. Competition training\n",
      "White Belt Wrestlers\n",
      "GYMs in New York\n",
      "Serious Question About Sweating\n",
      "Does it make sense to go for the choke in this position?\n",
      "Why doesn’t Oliver Taza get more credit/recognition\n",
      "Teaching Styles - The Shintaro Higashi Show\n",
      "Best No-Gi School in the Research Triangle Park Area (North Carolina)\n",
      "Last Second Sweep Defense\n",
      "Episode 75: Dani Olafson - Jiu Jitsu Confidence, Ultra Running, and Why Women Should Grapple\n",
      "Guard Retention Help!\n",
      "Craig Jones discussing the constraints-led approach.\n",
      "Anyone know if BJJTees is still in business?\n",
      "Reoccurring Staph Infections. PLEASE HELP!\n",
      "Any recommendations for BJJ gyms in central Tokyo.\n",
      "Did anyone do anything similar to me?\n",
      "I'm pretty sure that in 10 years time, Danaher Death Squad is going to sound really cringe\n",
      "Love the idea of this instructional from AOJ. Detailed look into competition preparation.\n",
      "Tournament Tuesday\n",
      "Side control armbars\n",
      "Electric Chair ⚡ at Grappling industrie Paris White belt division\n",
      "What do you think about legalizing Daki Age as a submission that ends when you lift your opponent up, over your head?\n",
      "Do you go for submissions on your rolls?\n",
      "How can you stop being a pushover ?\n",
      "Physical 100 wrestler tries BJJ (Jang Eun Sil)\n",
      "What are some good constraint-based learning games?\n",
      "Do you have guys at the gym that avoid you when it comes time to roll because you submitted them a couple of times?\n",
      "Comp Rules Regarding Takedowns\n",
      "PSA: get on the Paul Schreiner instructionals.\n",
      "How well do you think Gordon would perform in MMA *IF* he was given basic striking training?\n",
      "I have to give a short speech at my belt ceremony. Any ideas on what to say, and what not to say?\n",
      "Too many MMA fighters have no respect for BJJ?\n",
      "Roger Gracie Breaks Down His ICONIC Match Against Buchecha\n",
      "Choke over chin\n",
      "Landed this O Goshi at an invitational.\n",
      "Denver BJJ Price\n",
      "Leglocks\n"
     ]
    }
   ],
   "source": [
    "#Get reddit data\n",
    "# TODO: add a logging script here\n",
    "requests.get('https://oauth.reddit.com/api/v1/me', headers=headers)\n",
    "\n",
    "res = requests.get('https://oauth.reddit.com/r/bjj/new',\n",
    "                 headers=headers, params={'limit':'100'})\n",
    "\n",
    "# Get new posts\n",
    "for post in res.json()['data']['children']:\n",
    "    print(post['data']['title'])\n",
    "\n",
    "#Create an empty dataframe to store the data: -> cols: the subreddit, the title of the post, the selftext of the post\n",
    "df = pd.DataFrame()\n",
    "new_rows = [\n",
    "    {\n",
    "        'subreddit': post['data']['subreddit'],\n",
    "        'title': post['data']['title'],\n",
    "        'selftext': post['data']['selftext']  # ,\n",
    "        # 'upvote_ratio': post['data']['upvote_ratio'],\n",
    "        # 'ups':post['data']['ups'],\n",
    "        # 'downs':post['data']['downs'],\n",
    "        # 'score':post['data']['score']\n",
    "    }\n",
    "    for post in res.json()['data']['children']\n",
    "]\n",
    "df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ikram\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Remove common English words using nltk stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
    "df['selftext'] = df['selftext'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Spacy to get names from titles and selftext column\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "people_names_title = []\n",
    "for text in df['title']:\n",
    "    doc = nlp(text)\n",
    "    people_names_title.extend(\n",
    "        entity.text for entity in doc.ents if entity.label_ == 'PERSON'\n",
    "    )\n",
    "\n",
    "people_names_selftext = []\n",
    "for text in df['selftext']:\n",
    "    doc = nlp(text)\n",
    "    people_names_selftext.extend(\n",
    "        entity.text for entity in doc.ents if entity.label_ == 'PERSON'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add names from data extracted in the Bjj Extraction repo and convert column to list\n",
    "names_df = pd.read_csv('practitioner_name.csv')\n",
    "names_list = names_df['practitioner_name'].tolist()\n",
    "names_list_lower = list(map(lambda x: x.lower(), names_list))\n",
    "\n",
    "# filter names_df to extract the names in the names_list csv\n",
    "names_df_title_df = df[df['title'].str.contains('|'.join(names_list))]\n",
    "names_df_selftext_df = df[df['selftext'].str.contains('|'.join(names_list))]\n",
    "\n",
    "# Concatenate two columns of the df into a new column containing names and comments-> merged -> separated by whitespace character ' '.\n",
    "df['merged'] = df['title'].str.cat(df['selftext'], sep=' ')\n",
    "\n",
    "# make all words lower case\n",
    "df['merged'] = df['title'].str.cat(df['selftext'], sep=' ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis using nltk Sentiment Intensity Analyzer and then further clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SentimentIntensityAnalyzer object\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any names mentioned data frame match up with whats in the names column \n",
    "results = []\n",
    "for text in df['merged']:\n",
    "    doc = nlp(text)\n",
    "    names_found = []\n",
    "    for token in doc:\n",
    "        token_lower = token.text.lower()\n",
    "        closest_match = difflib.get_close_matches(token_lower, names_list_lower)\n",
    "        if token_lower in names_list_lower:\n",
    "            names_found.append(token.text)\n",
    "        elif closest_match:\n",
    "            names_found.append(names_list[names_list_lower.index(closest_match[0])])\n",
    "    if len(names_found) > 0:\n",
    "        positive_words = [word for word in text.split() if sia.polarity_scores(word)['pos'] > 0]\n",
    "        results.append({'names': names_found, 'positive_words': positive_words})\n",
    "        \n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                    []\n",
       "1     [Inspired, like, flexibility,, favorite, giggl...\n",
       "2     [good, better, like, Hoping, enthusiasts, like...\n",
       "3                                                    []\n",
       "4                                    [kind, hope, sure]\n",
       "                            ...                        \n",
       "78                                         [well, like]\n",
       "79                    [respect, Like, LIKE, methodical]\n",
       "80                                                   []\n",
       "81                             [interested, like, fair]\n",
       "82                                                   []\n",
       "Name: positive_words, Length: 83, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results['positive_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From list of words in positive_words, find words that need to be manually removed\n",
    "common_words = [\n",
    "    \"create\",\n",
    "    \"please\",\n",
    "    \"help\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rows from lists to strings\n",
    "df_results['names'] = df_results['names'].apply(lambda x: ', '.join(x))\n",
    "df_results['positive_words'] = df_results['positive_words'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# convert positive_words_replaced with positive words and unpacked_names with names\n",
    "# define a function to remove punctuation except commas from a string\n",
    "def remove_punctuation_from_string(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation.replace(',', '')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>positive_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sam McNally, Maxine Thylin, Enson Inoue</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daniel Otero, Ryan Gracie, Manuel Pontes, Nyja...</td>\n",
       "      <td>Inspired, like, flexibility,, favorite, giggle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dany Gerard, Kira Sung, Ben Baxter, Andre Motta</td>\n",
       "      <td>good, better, like, Hoping, enthusiasts, like,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eduardo Tinoco</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eliot Marshall, Alex Martins</td>\n",
       "      <td>kind, hope, sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Gordon Ryan, Pedro Ramalho, Ryan Hall, Ryan Ha...</td>\n",
       "      <td>well, like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Tiago Alves</td>\n",
       "      <td>respect, Like, LIKE, methodical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Ryan Gracie</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Amal Easton, Amal Easton</td>\n",
       "      <td>interested, like, fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Fabio Gurgel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                names  \\\n",
       "0             Sam McNally, Maxine Thylin, Enson Inoue   \n",
       "1   Daniel Otero, Ryan Gracie, Manuel Pontes, Nyja...   \n",
       "2     Dany Gerard, Kira Sung, Ben Baxter, Andre Motta   \n",
       "3                                      Eduardo Tinoco   \n",
       "4                        Eliot Marshall, Alex Martins   \n",
       "..                                                ...   \n",
       "78  Gordon Ryan, Pedro Ramalho, Ryan Hall, Ryan Ha...   \n",
       "79                                        Tiago Alves   \n",
       "80                                        Ryan Gracie   \n",
       "81                           Amal Easton, Amal Easton   \n",
       "82                                       Fabio Gurgel   \n",
       "\n",
       "                                       positive_words  \n",
       "0                                                      \n",
       "1   Inspired, like, flexibility,, favorite, giggle...  \n",
       "2   good, better, like, Hoping, enthusiasts, like,...  \n",
       "3                                                      \n",
       "4                                    kind, hope, sure  \n",
       "..                                                ...  \n",
       "78                                         well, like  \n",
       "79                    respect, Like, LIKE, methodical  \n",
       "80                                                     \n",
       "81                             interested, like, fair  \n",
       "82                                                     \n",
       "\n",
       "[83 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuation, common words and empty rows\n",
    "\n",
    "# define a function to remove punctuation except commas from a list of strings\n",
    "def remove_punctuation_from_list(lst):\n",
    "    return [remove_punctuation_from_string(text) for text in lst]\n",
    "\n",
    "# create a set of the common bjj words\n",
    "common_words_set = set(common_words)\n",
    "\n",
    "# define a function to remove the common bjj words from a list of strings\n",
    "def remove_common_words(words):\n",
    "    # split the input string into a list of words\n",
    "    words_list = words.split()\n",
    "    \n",
    "    # remove non-alphanumeric characters from each word in the list\n",
    "    words_list = [''.join(filter(str.isalnum, word)) for word in words_list]\n",
    "    \n",
    "    # remove the common bjj words from the list of words\n",
    "    words_list = [word for word in words_list if word.lower() not in common_words_set]\n",
    "    \n",
    "    # join the remaining words into a string separated by commas and return it\n",
    "    return ', '.join(words_list)\n",
    "\n",
    "\n",
    "# apply the remove_common_words function to the 'positive_words' column of the dataframe\n",
    "df_results['positive_words_replaced'] = df_results['positive_words'].apply(remove_common_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>positive_words</th>\n",
       "      <th>positive_words_replaced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sam McNally, Maxine Thylin, Enson Inoue</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daniel Otero, Ryan Gracie, Manuel Pontes, Nyja...</td>\n",
       "      <td>Inspired, like, flexibility,, favorite, giggle...</td>\n",
       "      <td>Inspired, like, flexibility, favorite, giggle,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dany Gerard, Kira Sung, Ben Baxter, Andre Motta</td>\n",
       "      <td>good, better, like, Hoping, enthusiasts, like,...</td>\n",
       "      <td>good, better, like, Hoping, enthusiasts, like,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eduardo Tinoco</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eliot Marshall, Alex Martins</td>\n",
       "      <td>kind, hope, sure</td>\n",
       "      <td>kind, hope, sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Gordon Ryan, Pedro Ramalho, Ryan Hall, Ryan Ha...</td>\n",
       "      <td>well, like</td>\n",
       "      <td>well, like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Tiago Alves</td>\n",
       "      <td>respect, Like, LIKE, methodical</td>\n",
       "      <td>respect, Like, LIKE, methodical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Ryan Gracie</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Amal Easton, Amal Easton</td>\n",
       "      <td>interested, like, fair</td>\n",
       "      <td>interested, like, fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Fabio Gurgel</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                names  \\\n",
       "0             Sam McNally, Maxine Thylin, Enson Inoue   \n",
       "1   Daniel Otero, Ryan Gracie, Manuel Pontes, Nyja...   \n",
       "2     Dany Gerard, Kira Sung, Ben Baxter, Andre Motta   \n",
       "3                                      Eduardo Tinoco   \n",
       "4                        Eliot Marshall, Alex Martins   \n",
       "..                                                ...   \n",
       "78  Gordon Ryan, Pedro Ramalho, Ryan Hall, Ryan Ha...   \n",
       "79                                        Tiago Alves   \n",
       "80                                        Ryan Gracie   \n",
       "81                           Amal Easton, Amal Easton   \n",
       "82                                       Fabio Gurgel   \n",
       "\n",
       "                                       positive_words  \\\n",
       "0                                                       \n",
       "1   Inspired, like, flexibility,, favorite, giggle...   \n",
       "2   good, better, like, Hoping, enthusiasts, like,...   \n",
       "3                                                       \n",
       "4                                    kind, hope, sure   \n",
       "..                                                ...   \n",
       "78                                         well, like   \n",
       "79                    respect, Like, LIKE, methodical   \n",
       "80                                                      \n",
       "81                             interested, like, fair   \n",
       "82                                                      \n",
       "\n",
       "                              positive_words_replaced  \n",
       "0                                                      \n",
       "1   Inspired, like, flexibility, favorite, giggle,...  \n",
       "2   good, better, like, Hoping, enthusiasts, like,...  \n",
       "3                                                      \n",
       "4                                    kind, hope, sure  \n",
       "..                                                ...  \n",
       "78                                         well, like  \n",
       "79                    respect, Like, LIKE, methodical  \n",
       "80                                                     \n",
       "81                             interested, like, fair  \n",
       "82                                                     \n",
       "\n",
       "[83 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.replace('', np.nan)\n",
    "df_results.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group rows by name and input into a new dataframe\n",
    "grouped = df_results[['names', 'positive_words_replaced']].groupby('names')['positive_words_replaced'].apply(list)\n",
    "df_results = pd.DataFrame({'names': grouped.index, 'positive_words_replaced': grouped.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split strings in names, make lowercase and group data\n",
    "df_results['names'] = df_results['names'].apply(lambda x: x.split(', '))\n",
    "df_results = df_results.explode('names')\n",
    "df_results = df_results.applymap(lambda x: x.lower() if type(x) == str else x)\n",
    "df_results = df_results.groupby('names', as_index=False).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>positive_words_replaced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ailson brites</td>\n",
       "      <td>[gained, surprised, abilities, advantage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alan moraes</td>\n",
       "      <td>[Inspired, like, flexibility, favorite, giggle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alan sanchez</td>\n",
       "      <td>[like, yes, good, hoping, giving, good, safe, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alec baulding</td>\n",
       "      <td>[join, energy, confidence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alex martins</td>\n",
       "      <td>[wow, like, thanks, inspired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>vanessa english</td>\n",
       "      <td>[honestly, love, appreciate, share, Thanks, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>vitor henrique</td>\n",
       "      <td>[strength, fresh, strongest, strength, top, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>vitor toledo</td>\n",
       "      <td>[gentle, optimal, recommend, want, yes, enjoyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>willis nunes</td>\n",
       "      <td>[gained, surprised, abilities, advantage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>xiong yuxing</td>\n",
       "      <td>[ensure, chance, win, strength, like, comforta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               names                            positive_words_replaced\n",
       "0      ailson brites          [gained, surprised, abilities, advantage]\n",
       "1        alan moraes  [Inspired, like, flexibility, favorite, giggle...\n",
       "2       alan sanchez  [like, yes, good, hoping, giving, good, safe, ...\n",
       "3      alec baulding                         [join, energy, confidence]\n",
       "4       alex martins                      [wow, like, thanks, inspired]\n",
       "..               ...                                                ...\n",
       "146  vanessa english  [honestly, love, appreciate, share, Thanks, pe...\n",
       "147   vitor henrique  [strength, fresh, strongest, strength, top, li...\n",
       "148     vitor toledo  [gentle, optimal, recommend, want, yes, enjoyi...\n",
       "149     willis nunes          [gained, surprised, abilities, advantage]\n",
       "150     xiong yuxing  [ensure, chance, win, strength, like, comforta...\n",
       "\n",
       "[151 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to count the number of words in a list of strings\n",
    "def count_words(words_list):\n",
    "    count = 0\n",
    "    for words in words_list:\n",
    "        for word in words.split():\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# apply the function to the column and create a new column called \"word_count\"\n",
    "df_results['word_count'] = df_results['positive_words_replaced'].apply(count_words)\n",
    "df_results = df_results.sort_values(by=['word_count'], ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>positive_words_replaced</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>penny thomas</td>\n",
       "      <td>Inspired, like, flexibility, favorite, giggle,...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heath pedigo</td>\n",
       "      <td>Inspired, like, flexibility, favorite, giggle,...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jeremy jackson</td>\n",
       "      <td>Inspired, like, flexibility, favorite, giggle,...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eric phan</td>\n",
       "      <td>Inspired, like, flexibility, favorite, giggle,...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claudio mattos</td>\n",
       "      <td>Inspired, like, flexibility, favorite, giggle,...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>nyjah rollins</td>\n",
       "      <td>want</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>kit dale</td>\n",
       "      <td>recommend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>rubens charles</td>\n",
       "      <td>shares</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>joel gingery</td>\n",
       "      <td>want</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>matt thornton</td>\n",
       "      <td>free</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              names                            positive_words_replaced  \\\n",
       "0      penny thomas  Inspired, like, flexibility, favorite, giggle,...   \n",
       "1      heath pedigo  Inspired, like, flexibility, favorite, giggle,...   \n",
       "2    jeremy jackson  Inspired, like, flexibility, favorite, giggle,...   \n",
       "3         eric phan  Inspired, like, flexibility, favorite, giggle,...   \n",
       "4    claudio mattos  Inspired, like, flexibility, favorite, giggle,...   \n",
       "..              ...                                                ...   \n",
       "146   nyjah rollins                                               want   \n",
       "147        kit dale                                          recommend   \n",
       "148  rubens charles                                             shares   \n",
       "149    joel gingery                                               want   \n",
       "150   matt thornton                                               free   \n",
       "\n",
       "     word_count  \n",
       "0           108  \n",
       "1           108  \n",
       "2           108  \n",
       "3           108  \n",
       "4           108  \n",
       "..          ...  \n",
       "146           1  \n",
       "147           1  \n",
       "148           1  \n",
       "149           1  \n",
       "150           1  \n",
       "\n",
       "[151 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results['positive_words_replaced'] = df_results['positive_words_replaced'].apply(lambda x: ', '.join(x))\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>positive_words_replaced</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Penny Thomas</td>\n",
       "      <td>Inspired, like, flexibility, favorite, giggle,...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heath Pedigo</td>\n",
       "      <td>Inspired, like, flexibility, favorite, giggle,...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeremy Jackson</td>\n",
       "      <td>Inspired, like, flexibility, favorite, giggle,...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eric Phan</td>\n",
       "      <td>Inspired, like, flexibility, favorite, giggle,...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Claudio Mattos</td>\n",
       "      <td>Inspired, like, flexibility, favorite, giggle,...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            names                            positive_words_replaced  \\\n",
       "0    Penny Thomas  Inspired, like, flexibility, favorite, giggle,...   \n",
       "1    Heath Pedigo  Inspired, like, flexibility, favorite, giggle,...   \n",
       "2  Jeremy Jackson  Inspired, like, flexibility, favorite, giggle,...   \n",
       "3       Eric Phan  Inspired, like, flexibility, favorite, giggle,...   \n",
       "4  Claudio Mattos  Inspired, like, flexibility, favorite, giggle,...   \n",
       "\n",
       "   word_count  \n",
       "0         108  \n",
       "1         108  \n",
       "2         108  \n",
       "3         108  \n",
       "4         108  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top 5 results, capitalize names and save as csv\n",
    "top_5_results = df_results.head(5).copy()\n",
    "top_5_results['names'] = top_5_results['names'].str.title()\n",
    "top_5_results.loc[:, 'names'] = top_5_results['names'].str.title()\n",
    "top_5_results.to_csv(\"top_10_results.csv\", index=False)\n",
    "top_5_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape images from website and save as a circle png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the web driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['penny-thomas',\n",
       " 'heath-pedigo',\n",
       " 'jeremy-jackson',\n",
       " 'eric-phan',\n",
       " 'claudio-mattos']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get names to pull from site in a format that works with appending to the dataframe\n",
    "df_results_top_5_copy = df_results.head(5).copy()\n",
    "df_results_top_5_copy['search_names'] = df_results_top_5_copy['names'].str.replace(' ', '-')\n",
    "\n",
    "search_names = []\n",
    "for name in df_results_top_5_copy['search_names']:\n",
    "    search_names.append(name)\n",
    "\n",
    "search_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.bjjheroes.com/bjj-fighters/penny-thomas',\n",
       " 'https://www.bjjheroes.com/bjj-fighters/heath-pedigo',\n",
       " 'https://www.bjjheroes.com/bjj-fighters/jeremy-jackson',\n",
       " 'https://www.bjjheroes.com/bjj-fighters/eric-phan',\n",
       " 'https://www.bjjheroes.com/bjj-fighters/claudio-mattos']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Site links\n",
    "main_site = \"https://www.bjjheroes.com/bjj-fighters/\"\n",
    "site_links = []\n",
    "for name in search_names:\n",
    "    site_links.append(main_site + name)\n",
    "site_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through list of website links, download the banner image of each site and crop into circle\n",
    "# output as a png\n",
    "numbers = [str(i) for i in range(1, 6)]\n",
    "for i, (link, number) in enumerate(zip(site_links, numbers)):\n",
    "    # open site\n",
    "    driver.get(link)\n",
    "    sleep(3)\n",
    "    xpath = \"/html/body/div[2]/div[1]/div/div[4]/div/div/div[1]/div/div/div[2]\"\n",
    "    \n",
    "    # Find the image element using the given XPath\n",
    "    image_element = driver.find_element(\"xpath\", xpath)\n",
    "    \n",
    "    # Get the URL of the image from the element's \"src\" attribute\n",
    "    image_url = image_element.get_attribute(\"style\")\n",
    "    try:\n",
    "        start_index = image_url.index('\"') + 1\n",
    "        end_index = image_url.index('\"', start_index)\n",
    "        url = image_url[start_index:end_index]\n",
    "    except ValueError:\n",
    "        print(f\"Error: image URL not found for site {link}\")\n",
    "        continue\n",
    "\n",
    "    # Download the image content\n",
    "    image_content = requests.get(url).content\n",
    "    \n",
    "    # Convert image content to Pillow Image object\n",
    "    image = Image.open(io.BytesIO(image_content))\n",
    "    \n",
    "    # Crop the image into a circle\n",
    "    width, height = image.size\n",
    "    circle_radius = min(width, height) // 2\n",
    "    mask = Image.new('L', (circle_radius*2, circle_radius*2), 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    draw.ellipse((0, 0, circle_radius*2, circle_radius*2), fill=255)\n",
    "    cropped_image = ImageOps.fit(image, (circle_radius*2, circle_radius*2), centering=(0.5, 0.5))\n",
    "    \n",
    "    # Apply mask to cropped image\n",
    "    rgba_image = Image.new('RGBA', (circle_radius*2, circle_radius*2), (0, 0, 0, 0))\n",
    "    rgba_image.paste(cropped_image, (0, 0), mask=mask)\n",
    "    \n",
    "    # Save the image to the specified file path\n",
    "    download_path = \"\"\n",
    "    file_name = f\"{number}.png\"\n",
    "    file_path = download_path + file_name\n",
    "    rgba_image.save(file_path)\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
